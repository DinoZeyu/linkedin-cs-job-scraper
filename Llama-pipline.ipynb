{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "528bde08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e48c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face to use LLaMA model\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(\"hf_your_token_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e081b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinkedin_jobs_demo.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m      2\u001b[0m text_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription“,”Responsibilities“,”QualificationsRequired“,”QualificationsPreferred“,”Requirements\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"linkedin_jobs_demo.csv\") \n",
    "text_columns = [\"Description“,”Responsibilities“,”QualificationsRequired“,”QualificationsPreferred“,”Requirements\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc28a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    dtype = \"bfloat16\",\n",
    "    load_in_4bit = True,\n",
    "    device_map = \"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "101091e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template for skill extraction\n",
    "\n",
    "def make_prompt(field_name, field_text):\n",
    "    return f\"\"\"\n",
    "You are an AI assistant that extracts **technical computer science skills** from job postings.\n",
    "\n",
    "Field: {field_name}\n",
    "Text: {field_text}\n",
    "\n",
    "Answer ONLY with a concise comma-separated list of skills (e.g., Python, TensorFlow, SQL).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column(row_dict):\n",
    "    \"\"\"This function processes each row and extracts skills from specified text columns.\n",
    "       It processes each column individually and aggregates the results to avoid token limit issues.\n",
    "     \"\"\"\n",
    "    skills_all = []\n",
    "    for col in text_columns:\n",
    "        field_text = str(row_dict.get(col, \"\"))\n",
    "        if field_text.strip() and field_text.lower() != \"nan\":\n",
    "            # Apply prompt template to specific task\n",
    "            prompt = make_prompt(col, field_text)\n",
    "\n",
    "            # Model inference, we could change max_new_tokens and do_sample for more diverse results\n",
    "            inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "            outputs = model.generate(**inputs, max_new_tokens=200, do_sample=False)\n",
    "\n",
    "            # Decode and clean up the output to extract skills\n",
    "            text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            skills = text.strip().split(\"\\n\")[-1]\n",
    "            skills_all.extend([s.strip() for s in skills.split(\",\") if s.strip()])\n",
    "\n",
    "    return \", \".join(sorted(set(skills_all)))\n",
    "\n",
    "\n",
    "# Parallel processing to speed up, n_jobs can be adjusted based on device capability\n",
    "results = Parallel(n_jobs=10, backend=\"threading\")(\n",
    "    delayed(process_column)(row) \n",
    "    for row in tqdm(df.to_dict(orient=\"records\"), desc=\"Extracting CS skills\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee671f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Extracted_Skills\"] = results\n",
    "df.to_csv(\"Linkedin_Job_Requirements_LLama.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
